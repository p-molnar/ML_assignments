{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2de29de",
   "metadata": {},
   "source": [
    "<center><h1>Assignment 2</h1></center>\n",
    "\n",
    "## Student details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce772440",
   "metadata": {},
   "source": [
    "## Generic environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment main dependencies\n",
    "import warnings # to suppress warning messages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dd3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore warnings in the notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4640af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib plotting config\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57420b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape sequences for text formatting\n",
    "BOLD = '\\033[1;3m'\n",
    "RESET_FMT = '\\033[0m'\n",
    "\n",
    "def print_bold(s):\n",
    "    print(f\"{BOLD}{s}{RESET_FMT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1125b",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "First we read the CSV file at hand into a Pandas DataFrame, `df`, via the `read_csv()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ec59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"OnlineNewsPopularity/OnlineNewsPopularity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50400f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0        1.0  ...   \n",
       "1                   0.791946         3.0              1.0        1.0  ...   \n",
       "2                   0.663866         3.0              1.0        1.0  ...   \n",
       "3                   0.665635         9.0              0.0        1.0  ...   \n",
       "4                   0.540890        19.0             19.0       20.0  ...   \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31871e3f",
   "metadata": {},
   "source": [
    "We observe, that the DataFrame contains 60 + 1 features, of which the target variable is called `shares`. Next, we query descriptive statistics on the DataFrame by the `describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30aa88fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.380184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11626.950749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "count  39644.000000     39644.000000       39644.000000      39644.000000   \n",
       "mean     354.530471        10.398749         546.514731          0.548216   \n",
       "std      214.163767         2.114037         471.107508          3.520708   \n",
       "min        8.000000         2.000000           0.000000          0.000000   \n",
       "25%      164.000000         9.000000         246.000000          0.470870   \n",
       "50%      339.000000        10.000000         409.000000          0.539226   \n",
       "75%      542.000000        12.000000         716.000000          0.608696   \n",
       "max      731.000000        23.000000        8474.000000        701.000000   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count       39644.000000               39644.000000  39644.000000   \n",
       "mean            0.996469                   0.689175     10.883690   \n",
       "std             5.231231                   3.264816     11.332017   \n",
       "min             0.000000                   0.000000      0.000000   \n",
       "25%             1.000000                   0.625739      4.000000   \n",
       "50%             1.000000                   0.690476      8.000000   \n",
       "75%             1.000000                   0.754630     14.000000   \n",
       "max          1042.000000                 650.000000    304.000000   \n",
       "\n",
       "        num_self_hrefs      num_imgs    num_videos  ...  \\\n",
       "count     39644.000000  39644.000000  39644.000000  ...   \n",
       "mean          3.293638      4.544143      1.249874  ...   \n",
       "std           3.855141      8.309434      4.107855  ...   \n",
       "min           0.000000      0.000000      0.000000  ...   \n",
       "25%           1.000000      1.000000      0.000000  ...   \n",
       "50%           3.000000      1.000000      0.000000  ...   \n",
       "75%           4.000000      4.000000      1.000000  ...   \n",
       "max         116.000000    128.000000     91.000000  ...   \n",
       "\n",
       "        min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "count            39644.000000            39644.000000            39644.000000   \n",
       "mean                 0.095446                0.756728               -0.259524   \n",
       "std                  0.071315                0.247786                0.127726   \n",
       "min                  0.000000                0.000000               -1.000000   \n",
       "25%                  0.050000                0.600000               -0.328383   \n",
       "50%                  0.100000                0.800000               -0.253333   \n",
       "75%                  0.100000                1.000000               -0.186905   \n",
       "max                  1.000000                1.000000                0.000000   \n",
       "\n",
       "        min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "count            39644.000000            39644.000000         39644.000000   \n",
       "mean                -0.521944               -0.107500             0.282353   \n",
       "std                  0.290290                0.095373             0.324247   \n",
       "min                 -1.000000               -1.000000             0.000000   \n",
       "25%                 -0.700000               -0.125000             0.000000   \n",
       "50%                 -0.500000               -0.100000             0.150000   \n",
       "75%                 -0.300000               -0.050000             0.500000   \n",
       "max                  0.000000                0.000000             1.000000   \n",
       "\n",
       "        title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "count               39644.000000             39644.000000   \n",
       "mean                    0.071425                 0.341843   \n",
       "std                     0.265450                 0.188791   \n",
       "min                    -1.000000                 0.000000   \n",
       "25%                     0.000000                 0.166667   \n",
       "50%                     0.000000                 0.500000   \n",
       "75%                     0.150000                 0.500000   \n",
       "max                     1.000000                 0.500000   \n",
       "\n",
       "        abs_title_sentiment_polarity         shares  \n",
       "count                   39644.000000   39644.000000  \n",
       "mean                        0.156064    3395.380184  \n",
       "std                         0.226294   11626.950749  \n",
       "min                         0.000000       1.000000  \n",
       "25%                         0.000000     946.000000  \n",
       "50%                         0.000000    1400.000000  \n",
       "75%                         0.250000    2800.000000  \n",
       "max                         1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845d422",
   "metadata": {},
   "source": [
    "Above, we see that the number of columns dropped to 60. This is becuase the `describe()` method cannot do descriptive statistics on a nominal variable, `url`. \n",
    "\n",
    "Below, we learn about the data types of the features by printing out the `dtypes` attribute of the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b65a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url                               object\n",
      " timedelta                       float64\n",
      " n_tokens_title                  float64\n",
      " n_tokens_content                float64\n",
      " n_unique_tokens                 float64\n",
      "                                  ...   \n",
      " title_subjectivity              float64\n",
      " title_sentiment_polarity        float64\n",
      " abs_title_subjectivity          float64\n",
      " abs_title_sentiment_polarity    float64\n",
      " shares                            int64\n",
      "Length: 61, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get data types of dataframe\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78fa40",
   "metadata": {},
   "source": [
    "Because the URL link of a website is irrelevant for our model, we decided to drop this feature from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e47158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant feature\n",
    "df = df.drop('url', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdaae3d",
   "metadata": {},
   "source": [
    "We can see that all of our data are of type \"float\", except for the target variable Shares, which is an integer. We will get to the conversion of the target variable into a categorical variable later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d3d74",
   "metadata": {},
   "source": [
    "Inpsecting the OnlineNewsPopularity.names file, as well as the data types we have just printed, we see that this dataset has features that correspond to categorical measures, such as the data channel of the news article or the day on which the article was published. However, it is also noticable that dummy variables have already been created for both of these measures in the dataset. Regarding data channels, we find the \"data_channel_is_...\" variables, where each variable represent a certain data channel, such as \"data_channel_is_lifestyle\", or \"data_channel_is_entertainment\". We find a similar encoding for the weekdays, where dummies have already been created in the dataset, such as \"weekday_is_monday\" or \"weekday_is_tuesday\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd61010",
   "metadata": {},
   "source": [
    "Next, we would like to convert our continuous target variable \"Shares\" into a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539b9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark's verison -> prone to error\n",
    "# df[' shares'] = pd.cut(x=df[' shares'], bins=[0, 1400, 99999999],\n",
    "#                      labels=[0,1])\n",
    "\n",
    "# convert target variable to binary\n",
    "df[' shares'] = (df[' shares'] >= 1400).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10186c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21154\n",
      "0    18490\n",
      "Name:  shares, dtype: int64 \n",
      "\n",
      "count    39644.000000\n",
      "mean         0.533599\n",
      "std          0.498876\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name:  shares, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[' shares'].value_counts(), '\\n')\n",
    "print(df[' shares'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed081709",
   "metadata": {},
   "source": [
    "Next, we create the target and feature DataFrames, by selecting the relevant columns of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294da0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select target and feature column(s)\n",
    "target_name = ' shares'\n",
    "target = df[target_name]\n",
    "feature = df.drop(target_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f851fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1233ce",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b23f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility cell\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "def populate_df(df, grid_search_obj, outcome):\n",
    "    \n",
    "    y_true, y_pred = outcome\n",
    "    \n",
    "    df.loc['Best parameter(s)', scl_name] = str(grid_search_obj.best_params_)\n",
    "    df.loc['Best cross-validation score', scl_name] = round(grid_search_obj.best_score_, 6)\n",
    "    df.loc['Best Training set score', scl_name] = round(grid_search_obj.score(X_train, y_train), 6)\n",
    "    df.loc['Best Test set score', scl_name] = round(grid_search_obj.score(X_test, y_test), 6)\n",
    "    \n",
    "    df.loc['Accuracy', scl_name] = round(accuracy_score(y_true, y_pred), 6)\n",
    "    df.loc['Macro-Averaged Precision', scl_name] = round(average_precision_score(y_true, y_pred, average='macro'), 6)\n",
    "    df.loc['Micro-Averaged Precision', scl_name] = round(average_precision_score(y_true, y_pred, average='micro'), 6)\n",
    "    df.loc['Recall', scl_name] = round(recall_score(y_true, y_pred), 6)\n",
    "    df.loc['F1 Score', scl_name] = round(f1_score(y_true, y_pred), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba57c9",
   "metadata": {},
   "source": [
    "Splitting the data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a61888f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig set size: 29733\n",
      "test set size: 9911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into a training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, random_state=8)\n",
    "print(\"trainig set size: {}\\ntest set size: {}\".format(y_train.shape[0], y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536999d0",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ee926",
   "metadata": {},
   "source": [
    "#### Unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548221e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'linearsvc__C': [10 ** n for n in range(-3, 4)]}\n",
    "\n",
    "linearsvc_unscaled_pipe = make_pipeline(LinearSVC())\n",
    "linearsvc_unscaled_grid = GridSearchCV(linearsvc_unscaled_pipe, param_grid, cv=10)\n",
    "linearsvc_unscaled_grid.fit(X_train, y_train)\n",
    "\n",
    "print_bold(\"LinearSVC model scores on unscaled data:\\n\")\n",
    "print(\"Best parameter(s): {}\".format(linearsvc_unscaled_grid.best_params_))\n",
    "print(\"Best estimator: {}\".format(linearsvc_unscaled_grid.best_estimator_))\n",
    "print(\"Best cross-validation score: {:.6f}\".format(linearsvc_unscaled_grid.best_score_))\n",
    "\n",
    "\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(linearsvc_unscaled_grid.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(linearsvc_unscaled_grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86aa57",
   "metadata": {},
   "source": [
    "#### Scaled data by `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "param_grid = {'linearsvc__C': [10 ** n for n in range(-3, 4)]}\n",
    "\n",
    "LinearSVC_Standard_pipe = make_pipeline(StandardScaler(), LinearSVC())\n",
    "grid_search = GridSearchCV(LinearSVC_Standard_pipe, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"StandardScaler scaled output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a0855",
   "metadata": {},
   "source": [
    "#### Scaled data by `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6802316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "param_grid = {'linearsvc__C': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "LinearSVC_MinMax_pipe = make_pipeline(MinMaxScaler(), LinearSVC())\n",
    "grid_search = GridSearchCV(LinearSVC_MinMax_pipe, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"MinMax scaled output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32cd1c",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683bc2e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2998e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                MinMaxScaler  \\\n",
      "Best parameter(s)            {'logisticregression__C': 1000}   \n",
      "Best cross-validation score                         0.652069   \n",
      "Best Training set score                             0.652575   \n",
      "Best Test set score                                 0.648572   \n",
      "Accuracy                                            0.648572   \n",
      "Macro-Averaged Precision                            0.623092   \n",
      "Micro-Averaged Precision                            0.623092   \n",
      "Recall                                              0.689962   \n",
      "F1 Score                                            0.676572   \n",
      "\n",
      "                                                    Unscaled  \\\n",
      "Best parameter(s)            {'logisticregression__C': 1000}   \n",
      "Best cross-validation score                         0.592036   \n",
      "Best Training set score                             0.592439   \n",
      "Best Test set score                                 0.587428   \n",
      "Accuracy                                            0.587428   \n",
      "Macro-Averaged Precision                            0.578156   \n",
      "Micro-Averaged Precision                            0.578156   \n",
      "Recall                                              0.678598   \n",
      "F1 Score                                            0.636695   \n",
      "\n",
      "                                            StandardScaler  \n",
      "Best parameter(s)            {'logisticregression__C': 10}  \n",
      "Best cross-validation score                       0.654121  \n",
      "Best Training set score                           0.656173  \n",
      "Best Test set score                               0.653617  \n",
      "Accuracy                                          0.653617  \n",
      "Macro-Averaged Precision                          0.627096  \n",
      "Micro-Averaged Precision                          0.627096  \n",
      "Recall                                            0.692235  \n",
      "F1 Score                                          0.680443  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mdl_name, mdl_obj = ('Logistic Regression', LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [10 ** n for n in range(-3, 4)]}\n",
    "scaler = [\n",
    "    ('Unscaled', None),\n",
    "    ('MinMaxScaler', MinMaxScaler()),\n",
    "    ('StandardScaler', StandardScaler())]\n",
    "\n",
    "for scl_name, scl_obj in scaler:\n",
    "    pipeline = make_pipeline(scl_obj, mdl_obj)\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    populate_df(model_scores_df, grid_search, (y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a63176",
   "metadata": {},
   "source": [
    "#### Unscaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"unscaled output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))\n",
    "\n",
    "# print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fcd23c",
   "metadata": {},
   "source": [
    "#### Scaled data by `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd03f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "Logreg_pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "grid_search = GridSearchCV(Logreg_pipe, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"StandardScaler output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08a5e8",
   "metadata": {},
   "source": [
    "#### Scaled data by `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "Logreg_pipe = make_pipeline(MinMaxScaler(), LogisticRegression())\n",
    "grid_search = GridSearchCV(Logreg_pipe, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"MinMaxScaler output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cdbc0",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f49ce7",
   "metadata": {},
   "source": [
    "#### Unscaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "param_grid = {\"n_neighbors\": range(3, 11)}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Knn GridSearchCV output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da097679",
   "metadata": {},
   "source": [
    "#### Scaled data by `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01c6660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler output\n",
      "\n",
      "Best parameters: {'kneighborsregressor__n_neighbors': 90}\n",
      "LinearSVC training set score: 0.130132\n",
      "LinearSVC test set score: 0.114285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "param_grid = {\"kneighborsregressor__n_neighbors\": range(0, 101, 5)}\n",
    "\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsRegressor())\n",
    "grid_search = GridSearchCV(knn_pipe, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"StandardScaler output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104f3eb",
   "metadata": {},
   "source": [
    "#### Scaled data by `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8facd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "param_grid = {\"kneighborsregressor__n_neighbors\": range(0, 101, 5)}\n",
    "\n",
    "knn_pipe = make_pipeline(MinMaxScaler(), KNeighborsRegressor())\n",
    "grid_search = GridSearchCV(knn_pipe, param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"StandardScaler output\\n\")\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"LinearSVC training set score: {:.6f}\".format(grid_search.score(X_train, y_train)))\n",
    "print(\"LinearSVC test set score: {:.6f}\".format(grid_search.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
